import math

import numpy as np
import pandas as pd
from app import Configuration
from app import app
from app.tasks.common_functions import fetch_db, misnomer_conversion, \
    check_in_std_cst, validate_pon, validate_depot, process_error_pon, \
    to_sql_customer_dna_record, read_sap_export_file, to_sql_sap_inventory, \
    add_hnad, to_sql_bom, read_data, to_sql_mtbf, to_sql_current_ib
from app.tasks.customer_dna import cleaned_dna_file
from celery import Celery
from sqlalchemy import create_engine

engine = create_engine(Configuration.INFINERA_DB_URL)
connection = Configuration.INFINERA_DB_URL


def make_celery(app):
    celery = Celery(app.import_name,
                    broker=app.config['CELERY_BROKER_URL'])
    celery.conf.update(app.config)
    TaskBase = celery.Task
    class ContextTask(TaskBase):
        abstract = True
        def __call__(self, *args, **kwargs):
            with app.app_context():
                return TaskBase.__call__(self, *args, **kwargs)
    celery.Task = ContextTask
    return celery

celery = make_celery(app)

def add_prospect(email_id):
    engine = create_engine(Configuration.INFINERA_DB_URL)
    selectquery = "select prospects_id FROM prospect_details where prospects_email='{0}'".format(email_id)
    result = engine.execute(selectquery).fetchone()
    if result is not None:
        return result[0]
    else:
        query = "insert into prospect_details (prospects_email) values('{0}')".format(email_id)
        engine.execute(query)
        result = engine.execute(selectquery).fetchone()
        return result[0]


def update_prospect_step(prospects_id, step_id, analysis_date):
    engine = create_engine(Configuration.INFINERA_DB_URL)
    try:
        selectquery = "select * FROM prospect_status where analysis_request_time='{0}'" \
                      "and prospects_id={1}".format(analysis_date, prospects_id)
        result = engine.execute(selectquery).fetchone()
        if result is None:
            query = "insert into prospect_status (prospects_id,prospects_step,analysis_request_time) values({0},{1},'{2}')".format(prospects_id,
                                                                                                 step_id, analysis_date)
            print(query)
            engine.execute(query)

        else:
            query = "update prospect_status set prospects_step = {0} where prospects_id = {1}" \
                    " and analysis_request_time='{2}'".format(step_id, prospects_id, analysis_date)
            print(query)
            engine.execute(query)

    except:
        print("Failed to update status for prospects_id {0}".format(prospects_id))



def shared_function(dna_file, sap_file, analysis_date, analysis_id, prospect_id, replenish_time):

    # 5.4 Load all Data elements from Reference Data
    (misnomer_pons, standard_cost, node, spared_pons, highspares, get_ratio_to_pon, parts,
     parts_cost, high_spares, depot) = fetch_db(replenish_time)

    # clean PONs, part# and installed equipments
    input_db = cleaned_dna_file(dna_file)


    # 5.5 Convert Misnomer PON to correct PON
    # PON with no misnomers
    input_with_no_misnomer_pon = misnomer_conversion(input_db, misnomer_pons)
    to_sql_customer_dna_record('customer_dna_record', input_db, analysis_date, analysis_id)

    update_prospect_step(prospect_id, 2, analysis_date)  # Dump customer_dna Table Status

    # 5.6 Apply Standard Cost Rule
    input_with_no_misnomer_pon = check_in_std_cst(input_with_no_misnomer_pon, standard_cost)

    # Assign PON to Installed equipments to remove any ambiguity
    input_with_no_misnomer_pon['InstalledEqpt'] = input_with_no_misnomer_pon['Product Ordering Name']

    # 5.7 Validate PONs and Depot
    valid_pon = validate_pon(input_with_no_misnomer_pon, analysis_date, analysis_id)

    # 5.8 Identify Valid Sparable Items and Identify Error Conditions

    # 5.8.1 Calculate node_to_depot
    valid_pon = pd.merge(valid_pon, node, left_on='Node Name', right_on='node_name', how='left')
    valid_pon = validate_depot(valid_pon, analysis_date, analysis_id)

    # Add node_depot_belongs attribute ,If True PON has depot name
    valid_pon['has_node_depot'] = False
    valid_pon.loc[(valid_pon['node_depot_belongs'].notna()), 'has_node_depot'] = True

    # 5.8.2 Collect attributes A) PON Has Std Cost or Not
    valid_pon = pd.merge(valid_pon, standard_cost, left_on=['Product Ordering Name'], right_on=['part_name'],
                         how='left')
    # Remove unnecessary column generated by merge

    valid_pon = valid_pon.drop(['created_at', 'updated_at', 'Source'], 1)
    valid_pon['has_std_cost'] = False
    valid_pon.loc[(valid_pon['standard_cost'].notna()), 'has_std_cost'] = True

    # 5.8.2 Collect attributes - B) PON is Sparrable or Not
    valid_pon['is_sparrable'] = False
    valid_pon = pd.merge(valid_pon, spared_pons, left_on=['Product Ordering Name'], right_on=['part_name'], how='inner')

    valid_pon.loc[(valid_pon['Product Ordering Name'] == valid_pon['part_name_x']), 'is_sparrable'] = True


    # Remove unnecessary column generated by merge
    valid_pon = valid_pon.drop(['part_name_x', 'part_name_y'], 1)

    # Keep only sparable pons
    valid_pon = valid_pon[valid_pon['is_sparrable'] == True]

    # all_valid conditions
    # PON with sparable, has_std_cost,has_node_depot and valid pon_name & depot name
    all_valid = valid_pon[((valid_pon['has_std_cost'] == True) & (valid_pon['has_node_depot'] == True))]

    invalid_pon = valid_pon[~((valid_pon['has_std_cost'] == True) & (valid_pon['has_node_depot'] == True))]

    # 5.9 Process Error Records - Store Invalid PONS with Proper Reason
    if not invalid_pon.empty:
        process_error_pon('error_records', invalid_pon, analysis_date, analysis_id)

    update_prospect_step(prospect_id, 3, analysis_date)  # Dump error_records Table Status

    # 5.9 Process Error Records - Compare Valid PON against

    sap_inventory = read_sap_export_file(sap_file)
    to_sql_sap_inventory('sap_inventory', sap_inventory, analysis_date,analysis_id)

    update_prospect_step(prospect_id, 4, analysis_date)  # Dump sap_inventory Table Status
    return all_valid, parts, get_ratio_to_pon, depot, high_spares, standard_cost


def bom_calcuation(dna_file, sap_file, analysis_date, analysis_id, prospect_id, replenish_time):



    all_valid, parts, get_ratio_to_pon, depot, high_spares, standard_cost = shared_function(dna_file, sap_file,
                                                                                            analysis_date, analysis_id,
                                                                                            prospect_id, replenish_time)

    Get_Fru = pd.DataFrame(
        all_valid.groupby(['Product Ordering Name', 'node_depot_belongs'])['node_depot_belongs'].count())
    Get_Fru.to_csv(Configuration.fruc_file_location, index=True)
    Get_Fru = pd.read_csv(Configuration.fruc_file_location)
    Get_Fru = Get_Fru.rename(columns={'node_depot_belongs.1': 'count'})
    Get_Fru.groupby(['Product Ordering Name', 'node_depot_belongs'])['count'].last().unstack(
        fill_value=0).stack().to_csv(Configuration.bom_table, header=True)
    get_bom_for_table = pd.read_csv(Configuration.bom_table)
    get_bom_for_table = get_bom_for_table.rename(columns={'0': 'PON Quanity'})
    #get_bom_for_table.to_csv("/Users/anup/eKryp/infinera/Parts-Analysis/data/install_base.csv", index=False)
    to_sql_current_ib('current_ib', get_bom_for_table, analysis_id)
    get_bom_for_table.rename(columns={
        'pon_quanity': 'PON Quanity',
        'product_ordering_name': 'Product Ordering Name'
    }, inplace=True
    )
    get_bom_for_table.drop(['request_id'], 1, inplace=True)
    return get_bom_for_table, get_ratio_to_pon, parts, depot, high_spares, standard_cost
    print('BOM calculation complete')


def simple_calculation(get_bom_for_table):
    get_bom_for_table.loc[get_bom_for_table['PON Quanity'] > 0, 'PON Quanity'] = 1
    get_bom_for_table.replace(np.nan, 0, inplace=True)
    get_bom_for_table = get_bom_for_table[['Product Ordering Name', 'node_depot_belongs', 'PON Quanity']]
    print("Simple Calculation")
    # print(get_bom_for_table)
    print("End Simple Calculation")
    return get_bom_for_table


def mtbf_calculation(get_bom_for_table, get_ratio_to_pon, parts):
    spare_cols = [str(x + 1) for x in range(10)]

    def find_spare_bin(row):
        bins = [0] + list(row[spare_cols])
        # Check for empyt count, if there is no calss family for PON
        # Then make required spared = 1, the logic is make the first column == FRU count
        # the return spare would be 1
        bins = [row['PON Quanity'] if math.isnan(x) else x for x in bins]
        return np.digitize(row['PON Quanity'], bins, right=True)

    Get_MTBF_BOM = pd.merge(get_bom_for_table, parts, left_on='Product Ordering Name', right_on='part_name', how='left')
    Get_MTBF_BOM = Get_MTBF_BOM[
        ['Product Ordering Name', 'node_depot_belongs', 'PON Quanity', 'part_reliability_class']]
    Get_MTBF_BOM = pd.merge(Get_MTBF_BOM, get_ratio_to_pon, left_on='part_reliability_class', right_on='product_family',
                            how='left')

    # If the reliability class is not found for a PON then we will assign a default count of 1
    Get_MTBF_BOM.loc[(Get_MTBF_BOM['part_reliability_class'].isna(), 'PON Quanity')] = 1

    Get_MTBF_BOM['PON Quanity'] = Get_MTBF_BOM.apply(find_spare_bin, axis=1)
    Get_MTBF_BOM_calc = Get_MTBF_BOM[['Product Ordering Name', 'node_depot_belongs', 'PON Quanity']]

    print("MTBF Calculation")
    # print(Get_MTBF_BOM_calc)
    print("End MTBF Calculation")
    return Get_MTBF_BOM_calc


def remove_hub_depot(df, depot):
    all_depots = pd.merge(df, depot, left_on='node_depot_belongs', right_on='depot_name', how='left')

    # PONs depots are HUB,hub=1 means they are HUB ,0 means they are not hub

    # Remove the PON which are in the below list
    # Make Pon quantity = 0 for PON in below list & their depot are not hub
    pon_list = ["DTC-ANSI-B=", "DTC-ETSI-B=", "OTC-ANSI-A=", "OTC-ETSI-A=", "XTC-2", "XTC-4",
                "XTC-10", "XTC-2E", "MTC-9-B", "MTC-6", "MPC-6", "MTC-9", "MTC-ANSI="]
    all_depots.loc[(all_depots['Product Ordering Name'].isin(pon_list)) & (all_depots['hub'] == 0), 'PON Quanity'] = 0

    # Keep only required columns
    all_depots = all_depots[['Product Ordering Name', 'node_depot_belongs', 'PON Quanity']]
    return all_depots

def calculate_shared_depot(single_bom, high_spares, standard_cost, parts, analysis_date, user_email_id, analysis_id, customer_name):

    '''
    step 1. first get parts and its high spare
    step 2. check if given part's quantity is !=0 if it not equal to 0 retain the value
    step 3. if given PON's quantity is 0 then get quantity from high spares
    step 4. quantity is either reorder point or total stock
    '''

    Connection = Configuration.ECLIPSE_DATA_DB_URI
    # step 1 get PON and its high spares - we will need
    # given_Spare name, high_spare_name, total_order_given, total_order_high, reorder_give, reorder_high_spare

    #get_zinventory_sql = 'SELECT storage_location,material_desc,total_stock,reorder_point FROM sap_inventory '
    #z_inventory = read_sap_export_file()
    get_zinventory_sql = 'SELECT storage_location,material_desc,total_stock,reorder_point FROM ' \
                         'sap_inventory where request_id={}'.format(analysis_id)
    z_inventory = read_data(get_zinventory_sql, Connection)
    z_inventory.rename(columns={
        'storage_location': 'Storage Location',
        'material_desc': 'Material Description',
        'total_stock': 'Total Stock',
        'reorder_point': 'Reorder Point'
    }, inplace=True
    )

    ''' This step is important because, when the inventory doesn't have reorder or total stock, the value is replaced - if Highs spare exists with
       high spare qty value if not replcae it with 0, but when we merge, the qty is null and the depot won't show up and grabbing value from high spare
       won't be possible, hence this step. '''

    '''
    This step gives us starting inventory
    '''
    # check if process 3 already stores the total inventory in databse then change the follwing line
    # to read from database instead of file -- For Ashish
    z_inventory.groupby(['Material Description', 'Storage Location'])['Total Stock', 'Reorder Point'].sum().unstack(
        fill_value=0).stack().to_csv(Configuration.shared_depot_file, header=True)
    sub = pd.read_csv(Configuration.shared_depot_file)

    # this step is to make sure that we take into account those depot that are present in the input file
    # but absent in inventory in which case all the qty in shared depot for missing inventory depot is marked zero

    #shared_depot = pd.merge(single_bom, z_inventory, left_on=['part_name','depot_name'], right_on=['Material Description','Storage Location'], how = 'left')
    shared_depot = single_bom

    # if the depot name is empty mark it with first occuring depot, set 0 to qty

    shared_depot = pd.merge(shared_depot, high_spares, left_on=['part_name'], right_on=['part_name'], how='left').merge(
        sub, left_on=['part_name', 'depot_name'], right_on=['Material Description', 'Storage Location'])

    shared_depot = pd.merge(shared_depot, sub, left_on=['high_spare', 'depot_name'], right_on=['Material Description', 'Storage Location'], how='left')
    shared_depot = shared_depot.replace(np.nan, 0)

    idx = (shared_depot['high_spare'] != 0)
    shared_depot.loc[idx, 'is_high_spares'] = True

    shared_depot = shared_depot.replace(np.nan, 0)

    shared_depot_total = shared_depot[['Total Stock_x', 'part_name', 'high_spare', 'Material Description_x', 'Total Stock_y', 'depot_name']]
    shared_depot_reorder = shared_depot[['Reorder Point_x', 'part_name', 'high_spare', 'Material Description_x', 'Reorder Point_y', 'depot_name','is_high_spares']]

    # only for for those pons that have high pons check if pon,s qty is 0, if 0 then grab shared depot qty
    # else keep depot qty

    shared_depot_total['Total Stock'] = shared_depot_total['Total Stock_x']
    idx = (shared_depot_total['Total Stock_x'] == 0)
    idx_pon_qty = (shared_depot_total['pon_quantity'] > 0)

    # set a flag to check if PON is 0 and another flag to check index of IB
    #shared_depot_total.loc[idx, 'using_highspare_for_totalstock'] = True

    shared_depot_total.loc[idx, 'is_inventory_zero'] = True
    shared_depot_total.loc[idx_pon_qty, 'has_IB'] = True

    shared_depot_total.loc[
        ((shared_depot_total['is_inventory_zero'] == True) & (
                    shared_depot_total['has_IB'] == True)), 'highspare_count_for_totalstock'] = shared_depot_total['Total Stock_y']
    shared_depot_total.loc[idx, 'Total Stock'] = shared_depot_total.loc[idx, 'Total Stock_y']

    
    shared_depot_reorder['Reorder Point'] = shared_depot_reorder['Reorder Point_x']
    idx = (shared_depot_reorder['Reorder Point_x'] == 0)
    shared_depot_reorder.loc[idx, 'is_inventory_zero'] = True
    shared_depot_reorder.loc[idx_pon_qty, 'has_IB'] = True


    shared_depot_reorder.loc[
        ((shared_depot_reorder['is_inventory_zero'] == True) & (
                    shared_depot_reorder['has_IB'] == True)), 'highspare_count_for_reorderpoint'] = shared_depot_reorder['Reorder Point_y']
    shared_depot_reorder.loc[idx, 'Reorder Point'] = shared_depot_reorder.loc[idx, 'Reorder Point_y']

    
    shared_depot_total = shared_depot_total[['part_name', 'Total Stock', 'depot_name']]
    shared_depot_reorder = shared_depot_reorder[['part_name', 'Reorder Point', 'depot_name','is_high_spares']]

    shared_depot = pd.merge(shared_depot_reorder, shared_depot_total, on=['part_name','depot_name'])

    single_bom = pd.merge(single_bom, shared_depot, on=['part_name', 'depot_name'])

    # if simple is selected
    # single_bom.loc[(single_bom['pon_quantity'] > 0), 'shared_quantity'] = single_bom['pon_quantity']
    # else when mtbf_bom is selected
    single_bom['shared_quantity'] = single_bom['pon_quantity']
    single_bom['net_total_stock'] = np.where(single_bom['shared_quantity'] - single_bom['Total Stock'] > 0, single_bom['shared_quantity'] - single_bom['Total Stock'], 0)
    single_bom['net_reorder_point'] = np.where(single_bom['shared_quantity'] - single_bom['Reorder Point'] > 0,single_bom['shared_quantity'] - single_bom['Reorder Point'], 0)

    # Get Part_number for summary table
    single_bom = pd.merge(single_bom, parts, on='part_name', how='left')
    single_bom = single_bom[['part_name', 'depot_name', 'Total Stock', 'Reorder Point',
                             'is_high_spares', 'shared_quantity', 'material_number', 'net_total_stock' , 'net_reorder_point']]

    # Get Part_Cost for summary table

    single_bom = pd.merge(single_bom, standard_cost, on='material_number', how='left')
    single_bom = single_bom[['part_name_x', 'depot_name', 'Total Stock', 'Reorder Point',
                             'is_high_spares', 'shared_quantity', 'material_number', 'net_total_stock', 'net_reorder_point', 'standard_cost']]

    single_bom['net_total_stock_cost'] = single_bom['net_total_stock'] * single_bom['standard_cost']
    single_bom['net_reorder_point_cost'] = single_bom['net_reorder_point'] * single_bom['standard_cost']
    # calculate high spare cost
    single_bom['High_spare_totalstock_cost'] = single_bom['highspare_count_for_totalstock'] * single_bom[
        'standard_cost']
    single_bom['High_spare_reoderpoint_cost'] = single_bom['highspare_count_for_reorderpoint'] * single_bom[
        'standard_cost']

    single_bom = single_bom.fillna(0)

    single_bom.rename(columns={
        'part_name_x': 'part_name',
        'is_high_spares':'high_spare',
        'Reorder Point':'reorder_point',
        'Total Stock':'total_stock'
    }, inplace=True
    )

    single_bom.loc[:, 'cust_id'] = 7
    single_bom.loc[:, 'analysis_request_time'] = analysis_date
    single_bom.loc[:, 'user_email_id'] = user_email_id
    single_bom.loc[:, 'request_id'] = analysis_id
    single_bom.loc[:, 'customer_name'] = customer_name

    # Make previous records for customer as not latest is_latest='N'
    # & new records getting inserted are by default is_latest='Y'

    engine = create_engine(Configuration.INFINERA_DB_URL)
    query = "update summary set is_latest='N' where customer_name='{0}'".format(customer_name)
    print(query)
    engine.execute(query)
    single_bom.to_sql(name='summary', con=engine, index=False, if_exists='append')
    print("Loaded data into summary table")

    # Initially make shared_
    # quantiity for all PON as 0,
    #single_bom['shared_quantity'] = 0
    #single_bom['is_high_spares'] = False
    # For PON in bom whose pon_quantity > 0 and has not having high spares
    # make shared quantity as bom explosion quantity
    #single_bom.loc[(single_bom['pon_quantity'] > 0) & (single_bom['high_spare'].isna()), 'shared_quantity'] = single_bom['pon_quantity']

    # For PON in bom whose pon_quantity > 0 and has having high spares
    # and not present in zinventory
    # make shared quantity as bom explosion quantity

    #single_bom.loc[(single_bom['pon_quantity'] > 0) & (single_bom['high_spare'].notnull()) & (single_bom['storage_location'].isna()), 'shared_quantity'] = single_bom['pon_quantity']

    # For PON in bom whose pon_quantity > 0 and has having high spares
    # and present in zinventory
    # check spared_part in present in same depot as bom & zinventory
    # make shared quantity as bom explosion quantity
    '''

    single_bom = single_bom[['part_name', 'depot_name', 'high_spare', 'total_stock', 'reorder_point', 'is_high_spares', 'shared_quantity']]
    single_bom['net_total_stock'] = single_bom['total_stock'] - single_bom['shared_quantity']
    single_bom['net_reorder_point'] = single_bom['reorder_point'] - single_bom['shared_quantity']

    # Get Part_number for summary table
    single_bom = pd.merge(single_bom, parts, on='part_name', how='left')
    single_bom = single_bom[['part_name', 'depot_name', 'total_stock', 'reorder_point',
                             'is_high_spares', 'shared_quantity', 'material_number', 'net_total_stock'
                             , 'net_reorder_point']]

    # Get Part_Cost for summary table

    single_bom = pd.merge(single_bom, standard_cost, on='material_number', how='left')
    single_bom = single_bom[['part_name_x', 'depot_name', 'total_stock', 'reorder_point',
                             'is_high_spares', 'shared_quantity', 'material_number','net_total_stock'
                             , 'net_reorder_point', 'standard_cost']]

    single_bom['net_total_stock_cost'] = single_bom['net_total_stock'] * single_bom['standard_cost']
    single_bom['net_reorder_point_cost'] = single_bom['net_reorder_point'] * single_bom['standard_cost']
    single_bom.rename(columns={
        'part_name_x': 'part_name',
        'is_high_spares': 'high_spare'
    }, inplace=True
    )
    single_bom['cust_id'] = 7
    single_bom.to_sql(name='summary', con=engine, index=False, if_exists='append')
    print("Loaded data into summary table")'''

'''  
def calculate_shared_depot(single_bom, high_spares, standard_cost, parts, analysis_date, user_email_id, analysis_id, customer_name):

    Connection = Configuration.ECLIPSE_DATA_DB_URI
    single_bom = pd.merge(single_bom, high_spares, on='part_name', how='left')
    get_zinventory_sql = 'SELECT storage_location,material_desc,total_stock,reorder_point FROM ' \
                         'sap_inventory where request_id={}'.format(analysis_id)
    z_inventory = read_data(get_zinventory_sql, Connection)
    single_bom = pd.merge(single_bom, z_inventory, left_on=['part_name', 'depot_name'],
                          right_on=['material_desc', 'storage_location'], how='left')

    # Initially make shared_quantiity for all PON as 0,
    single_bom['shared_quantity'] = 0
    single_bom['is_high_spares'] = False
    # For PON in bom whose pon_quantity > 0 and has not having high spares
    # make shared quantity as bom explosion quantity
    single_bom.loc[(single_bom['pon_quantity'] > 0) & (single_bom['high_spare'].isna()), 'shared_quantity'] = \
    single_bom['pon_quantity']

    # For PON in bom whose pon_quantity > 0 and has having high spares
    # and not present in zinventory
    # make shared quantity as bom explosion quantity

    single_bom.loc[(single_bom['pon_quantity'] > 0) & (single_bom['high_spare'].notnull()) & (
    single_bom['storage_location'].isna()), 'shared_quantity'] = single_bom['pon_quantity']

    # For PON in bom whose pon_quantity > 0 and has having high spares
    # and present in zinventory
    # check spared_part in present in same depot as bom & zinventory
    # make shared quantity as bom explosion quantity
    single_bom.loc[(single_bom['pon_quantity'] > 0) & (single_bom['high_spare'].notnull()) & (
    single_bom['storage_location'].notnull()) & (
                   single_bom['depot_name'] == single_bom['storage_location']), 'shared_quantity'] = single_bom[
        'pon_quantity']
    single_bom.loc[(single_bom['total_stock'].isna()), 'total_stock'] = 0
    single_bom.loc[(single_bom['reorder_point'].isna()), 'reorder_point'] = 0
    single_bom.loc[(single_bom['high_spare'].notnull()), 'is_high_spares'] = True

    single_bom = single_bom[
        ['part_name', 'depot_name', 'high_spare', 'total_stock', 'reorder_point', 'is_high_spares', 'shared_quantity']]
    single_bom['net_total_stock'] = single_bom['total_stock'] - single_bom['shared_quantity']
    single_bom['net_reorder_point'] = single_bom['reorder_point'] - single_bom['shared_quantity']

    # Get Part_number for summary table
    single_bom = pd.merge(single_bom, parts, on='part_name', how='left')
    single_bom = single_bom[['part_name', 'depot_name', 'total_stock', 'reorder_point',
                             'is_high_spares', 'shared_quantity', 'material_number', 'net_total_stock'
        , 'net_reorder_point']]

    # Get Part_Cost for summary table

    single_bom = pd.merge(single_bom, standard_cost, on='material_number', how='left')
    single_bom = single_bom[['part_name_x', 'depot_name', 'total_stock', 'reorder_point',
                             'is_high_spares', 'shared_quantity', 'material_number', 'net_total_stock'
        , 'net_reorder_point', 'standard_cost']]

    single_bom['net_total_stock_cost'] = single_bom['net_total_stock'] * single_bom['standard_cost']
    single_bom['net_reorder_point_cost'] = single_bom['net_reorder_point'] * single_bom['standard_cost']
    single_bom.rename(columns={
        'part_name_x': 'part_name',
        'is_high_spares': 'high_spare'
    }, inplace=True
    )
    #single_bom['cust_id'] = 7
    single_bom.loc[:, 'cust_id'] = 7
    single_bom.loc[:, 'analysis_request_time'] = analysis_date
    single_bom.loc[:, 'user_email_id'] = user_email_id
    single_bom.loc[:, 'request_id'] = analysis_id
    single_bom.loc[:, 'customer_name'] = customer_name
    single_bom.to_sql(name='summary', con=engine, index=False, if_exists='append')
    print("Loaded data into summary table")
    
'''

def get_bom(dna_file, sap_file, analysis_date, analysis_id, prospect_id, replenish_time):

    bom, get_ratio_to_pon, parts, depot, high_spares, standard_cost = bom_calcuation(dna_file, sap_file,
                                                                                     analysis_date, analysis_id,
                                                                                     prospect_id, replenish_time)

    # Flag will be there to choose from simple or mtbf calculation.
    '''
    gross_depot = simple_calculation(bom)

    # 5.13 Accommodating for Corporate and Regional Disti - Process 13
    
    gross_depot = remove_hub_depot(gross_depot, depot)
    gross_depot_hnad = add_hnad(gross_depot, quantity=1)
    to_sql_bom('bom_calculated', gross_depot_hnad, analysis_date, analysis_id)
    return gross_depot_hnad, high_spares, standard_cost, parts
    '''


    gross_depot = mtbf_calculation(bom, get_ratio_to_pon, parts)

    #5.13 Accommodating for Corporate and Regional Disti - Process 13

    gross_depot = remove_hub_depot(gross_depot, depot)
    gross_depot_hnad = add_hnad(gross_depot, quantity=1)
    to_sql_mtbf('mtbf_bom_calculated', gross_depot_hnad, analysis_date, analysis_id)
    return gross_depot_hnad, high_spares, standard_cost, parts


@celery.task
def derive_table_creation(dna_file, sap_file, analysis_date, user_email_id, analysis_id, customer_name, prospect_id, replenish_time):
    try:
        def set_request_status(status, analysis_id):
            engine = create_engine(Configuration.INFINERA_DB_URL)
            query = "update analysis_request set requestStatus='{0}' " \
                "where analysis_request_id = {1}".format(status, analysis_id)
            print(query)
            engine.execute(query)

        single_bom, high_spares, standard_cost, parts = get_bom(dna_file, sap_file, analysis_date, analysis_id, prospect_id, replenish_time)
        update_prospect_step(prospect_id, 5, analysis_date)  # BOM calculation Status
        calculate_shared_depot(single_bom, high_spares, standard_cost, parts, analysis_date,
                           user_email_id, analysis_id, customer_name)

        update_prospect_step(prospect_id, 6, analysis_date)  # Summary Calculation  Status
        set_request_status('Completed', analysis_id)

    except Exception as e:
        print("SOME ERROR OCCURRED")
        print(150 * "*")
        print(str(e))
        set_request_status('Failed', analysis_id)
        print(150 * "*")








